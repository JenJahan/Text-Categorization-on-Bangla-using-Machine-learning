{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import logging\n",
    "from numpy import random\n",
    "#import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39991, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.isnull().sum()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bangladesh            12239\n",
      "opinion               10611\n",
      "economy                4771\n",
      "sports                 3349\n",
      "entertainment          2447\n",
      "technology             2113\n",
      "international          1835\n",
      "life-style             1121\n",
      "education               774\n",
      "art-and-literature      366\n",
      "northamerica            189\n",
      "durporobash             176\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "data.Label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['opinion', 'economy', 'bangladesh', 'sports', 'entertainment',\n",
       "       'life-style', 'international', 'art-and-literature',\n",
       "       'northamerica', 'technology', 'education', 'durporobash'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = data.Label.unique()\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [\"!\", \"@\",'–', \"#\", \"|\", \"%\", \"(\", \")\", \"।\", \"—\", \".\", \"-\", \"\", \",\", \"’\", \"•\", \"‘\", \":\", \"*\", \"?\",\n",
    "          \"০\", \"১\", \"২\", \"৩\", \"৪\", \"৫\", \"৬\", \"৭\", \"৮\", \"৯\"]\n",
    "for i in range(len(p)):\n",
    "    data['Text'] = data['Text'].str.replace(p[i],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17153219"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['split'] = np.random.randn(data.shape[0], 1)\n",
    "msk = np.random.rand(len(data)) <= 0.25\n",
    "d1 = data[msk]\n",
    "d2 = data[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of rows\n",
    "# here you get 75% of the rows\n",
    "train = d1.sample(frac=0.75, random_state=99)\n",
    "test = d1.loc[~d1.index.isin(train.index), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train.shape[0]\n",
    "test_size  = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7415, 2472)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7415, 11726)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting features from text files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train['Text'].values.astype('U'))\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7415, 11726)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "# Training Naive Bayes (NB) classifier on training data.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
    "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
    "# We will be using the 'text_clf' going forward.\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train['Text'].values.astype('U'), train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5432847896440129"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of NB Classifier\n",
    "predicted = text_clf.predict(test['Text'].values.astype('U'))\n",
    "np.mean(predicted == test.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5432847896440129\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           opinion       0.00      0.00      0.00        23\n",
      "           economy       0.63      0.86      0.73       724\n",
      "        bangladesh       0.00      0.00      0.00        11\n",
      "            sports       1.00      0.17      0.28       302\n",
      "     entertainment       0.00      0.00      0.00        42\n",
      "        life-style       1.00      0.01      0.02       164\n",
      "     international       0.00      0.00      0.00       125\n",
      "art-and-literature       0.00      0.00      0.00        66\n",
      "      northamerica       0.00      0.00      0.00        10\n",
      "        technology       0.45      0.94      0.61       662\n",
      "         education       1.00      0.19      0.32       218\n",
      "       durporobash       1.00      0.04      0.08       125\n",
      "\n",
      "          accuracy                           0.54      2472\n",
      "         macro avg       0.42      0.18      0.17      2472\n",
      "      weighted avg       0.63      0.54      0.44      2472\n",
      "\n",
      "Wall time: 84.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('accuracy %s' % accuracy_score(predicted, test.Label))\n",
    "print(classification_report(test.Label, predicted,target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900485436893204"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Support Vector Machines - SVM and calculating its performance\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=15, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(train['Text'].values.astype('U'), train['Label'].values.astype('U'))\n",
    "predicted_svm = text_clf_svm.predict(test['Text'].values.astype('U'))\n",
    "np.mean(predicted_svm == test['Label'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7900485436893204\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           opinion       1.00      0.04      0.08        23\n",
      "           economy       0.77      0.88      0.82       724\n",
      "        bangladesh       0.00      0.00      0.00        11\n",
      "            sports       0.80      0.79      0.80       302\n",
      "     entertainment       1.00      0.12      0.21        42\n",
      "        life-style       0.88      0.76      0.82       164\n",
      "     international       1.00      0.06      0.12       125\n",
      "art-and-literature       0.91      0.45      0.61        66\n",
      "      northamerica       0.00      0.00      0.00        10\n",
      "        technology       0.74      0.92      0.82       662\n",
      "         education       0.89      0.95      0.92       218\n",
      "       durporobash       0.84      0.75      0.79       125\n",
      "\n",
      "          accuracy                           0.79      2472\n",
      "         macro avg       0.74      0.48      0.50      2472\n",
      "      weighted avg       0.80      0.79      0.76      2472\n",
      "\n",
      "Wall time: 84.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('accuracy %s' % accuracy_score(predicted_svm, test.Label))\n",
    "print(classification_report(test.Label, predicted_svm,target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "# Here, we are creating a list of parameters for which we would like to do performance tuning. \n",
    "# All the parameters name start with the classifier name (remember the arbitrary name we gave). \n",
    "# E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train['Text'].values.astype('U'), train['Label'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# To see the best mean score and the params, run the following code\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961165048543689"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = gs_clf.predict(test['Text'].values.astype('U'))\n",
    "np.mean(predicted == test.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7961165048543689\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           opinion       1.00      0.04      0.08        23\n",
      "           economy       0.83      0.84      0.84       724\n",
      "        bangladesh       0.00      0.00      0.00        11\n",
      "            sports       0.89      0.78      0.83       302\n",
      "     entertainment       0.80      0.38      0.52        42\n",
      "        life-style       0.95      0.76      0.84       164\n",
      "     international       0.94      0.23      0.37       125\n",
      "art-and-literature       0.95      0.55      0.69        66\n",
      "      northamerica       1.00      0.20      0.33        10\n",
      "        technology       0.66      0.96      0.78       662\n",
      "         education       0.98      0.89      0.93       218\n",
      "       durporobash       0.89      0.70      0.78       125\n",
      "\n",
      "          accuracy                           0.80      2472\n",
      "         macro avg       0.82      0.53      0.58      2472\n",
      "      weighted avg       0.82      0.80      0.78      2472\n",
      "\n",
      "Wall time: 98.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('accuracy %s' % accuracy_score(predicted, test.Label))\n",
    "print(classification_report(test.Label, predicted,target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Similarly doing grid search for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(train['Text'].values.astype('U'), train['Label'].values.astype('U'))\n",
    "\n",
    "\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900485436893204"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svm = gs_clf_svm.predict(test['Text'].values.astype('U'))\n",
    "np.mean(predicted_svm == test['Label'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7900485436893204\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           opinion       1.00      0.04      0.08        23\n",
      "           economy       0.77      0.88      0.82       724\n",
      "        bangladesh       0.00      0.00      0.00        11\n",
      "            sports       0.80      0.79      0.80       302\n",
      "     entertainment       1.00      0.12      0.21        42\n",
      "        life-style       0.88      0.76      0.82       164\n",
      "     international       1.00      0.06      0.12       125\n",
      "art-and-literature       0.91      0.45      0.61        66\n",
      "      northamerica       0.00      0.00      0.00        10\n",
      "        technology       0.74      0.92      0.82       662\n",
      "         education       0.89      0.95      0.92       218\n",
      "       durporobash       0.84      0.75      0.79       125\n",
      "\n",
      "          accuracy                           0.79      2472\n",
      "         macro avg       0.74      0.48      0.50      2472\n",
      "      weighted avg       0.80      0.79      0.76      2472\n",
      "\n",
      "Wall time: 100 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('accuracy %s' % accuracy_score(predicted_svm, test.Label))\n",
    "print(classification_report(test.Label, predicted_svm,target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5865695792880259"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "# Create Decision Tree classifer object\n",
    "text_clf_dt = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-dt', DecisionTreeClassifier(criterion='gini',splitter='best',\n",
    "                                                           max_depth=20))])\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "text_clf_dt = text_clf_dt.fit(train['Text'].values.astype('U'), train['Label'].values.astype('U'))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "predicted_dt = text_clf_dt.predict(test['Text'].values.astype('U'))\n",
    "np.mean(predicted_dt == test['Label'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5865695792880259\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           opinion       0.07      0.04      0.05        23\n",
      "           economy       0.62      0.72      0.66       724\n",
      "        bangladesh       0.00      0.00      0.00        11\n",
      "            sports       0.50      0.52      0.51       302\n",
      "     entertainment       0.21      0.21      0.21        42\n",
      "        life-style       0.59      0.50      0.54       164\n",
      "     international       0.22      0.10      0.14       125\n",
      "art-and-literature       0.43      0.44      0.44        66\n",
      "      northamerica       0.08      0.10      0.09        10\n",
      "        technology       0.67      0.70      0.68       662\n",
      "         education       0.72      0.56      0.63       218\n",
      "       durporobash       0.44      0.46      0.45       125\n",
      "\n",
      "          accuracy                           0.59      2472\n",
      "         macro avg       0.38      0.36      0.37      2472\n",
      "      weighted avg       0.57      0.59      0.58      2472\n",
      "\n",
      "Wall time: 84.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('accuracy %s' % accuracy_score(predicted_dt, test.Label))\n",
    "print(classification_report(test.Label, predicted_dt,target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8211974110032363"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "text_clf_lr = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf-lr', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "text_clf_lr = text_clf_lr.fit(train['Text'].values.astype('U'), train['Label'].values.astype('U'))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "predicted_lr = text_clf_lr.predict(test['Text'].values.astype('U'))\n",
    "np.mean(predicted_lr == test['Label'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8211974110032363\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           opinion       0.70      0.30      0.42        23\n",
      "           economy       0.83      0.84      0.84       724\n",
      "        bangladesh       0.50      0.18      0.27        11\n",
      "            sports       0.77      0.78      0.78       302\n",
      "     entertainment       0.65      0.57      0.61        42\n",
      "        life-style       0.88      0.82      0.85       164\n",
      "     international       0.72      0.50      0.59       125\n",
      "art-and-literature       0.78      0.74      0.76        66\n",
      "      northamerica       0.50      0.30      0.37        10\n",
      "        technology       0.83      0.89      0.86       662\n",
      "         education       0.94      0.94      0.94       218\n",
      "       durporobash       0.78      0.82      0.80       125\n",
      "\n",
      "          accuracy                           0.82      2472\n",
      "         macro avg       0.74      0.64      0.67      2472\n",
      "      weighted avg       0.82      0.82      0.82      2472\n",
      "\n",
      "Wall time: 84.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('accuracy %s' % accuracy_score(predicted_lr, test.Label))\n",
    "print(classification_report(test.Label, predicted_lr,target_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
